{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "af26f0cc-a405-4042-b48e-ee6fdb552825",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pypdf\n",
      "  Downloading pypdf-4.1.0-py3-none-any.whl.metadata (7.4 kB)\n",
      "Downloading pypdf-4.1.0-py3-none-any.whl (286 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m286.1/286.1 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0mm\n",
      "\u001b[?25hInstalling collected packages: pypdf\n",
      "Successfully installed pypdf-4.1.0\n"
     ]
    }
   ],
   "source": [
    "!pip install pypdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1c6c8f23-3905-4b59-9e0c-672bdb63623b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PatrickYaminLosAngeles,CA\n",
      "|909-569-4815|patrickyamin@gmail.c om|Github|Substack|LinkedIn\n",
      "DataScientist||MLEngineerExperienceindatamining,deeplearning ,machinelearning ,recommendersystemsandNLP.Withabackgroundinanalytics,supplychainlogistics,andsales,Ibringstrongskillsinengineeringandtrainingmachinelearningpipelinesthathelpcompaniesacrossvariousindustriesdriveinnovation,efficiency,andsustainabilitythroughdata-drivensolutions.\n",
      "TECHNICALSKILLSSkills:Python(Numpy,Pandas,Scikit-Learn,Torch,Keras,OOP),Bash,Cuda,Scripting,Virtualiz ation,Docker,Tableau,Excel,SQL(mySQL,Postgres,sqlite)OS:Linux(arch,debian,pop,ubuntu),Mac,WindowsLanguag es:English:NativeArabic:ProficientSpanish:LimitedProficiencyFrench:LimitedProficiency\n",
      "TECHNICALPROJECTSSemantico(SemanticSearchEnginewithRetrieval/Reranker)-GithubBuiltasearchenginefromvectorembeddingstomakesearchqueriesmoreefficientoverdocumen ts\n",
      "●DatacollectedfromAPIcallstoWikipedia\n",
      "●TrainedaBPE(byte-pairencoding)tokenizerwithSentencePiece\n",
      "●UsedSentenceTransformersaSOTAPyTorchframeworktobuildendtoendsearchpipeline\n",
      "PitchSequencePredictor-Github\n",
      "Used\n",
      "a\n",
      "neural\n",
      "network\n",
      "MLP\n",
      "with\n",
      "scikit-learn\n",
      "to\n",
      "predict\n",
      "the\n",
      "next\n",
      "pitch\n",
      "in\n",
      "the\n",
      "at\n",
      "bat \n",
      "●\n",
      "Web\n",
      "scraped\n",
      "data\n",
      "with\n",
      "Python\n",
      "package\n",
      "pybaseball\n",
      "from\n",
      "the\n",
      "2023\n",
      "MLB\n",
      "season \n",
      "●\n",
      "Built\n",
      "an\n",
      "XGBoost\n",
      "pipeline\n",
      "that\n",
      "achieved\n",
      "60%\n",
      "validation\n",
      "accuracy \n",
      "●\n",
      "Cross\n",
      "validated\n",
      "with\n",
      "sklearn\n",
      "GridSearchCV\n",
      "and\n",
      "RandomizedSearchCV\n",
      "IMDbFilmStatisticalAnalysis-Github\n",
      "Analyze\n",
      "movie\n",
      "databases\n",
      "in\n",
      "order\n",
      "to\n",
      "maximize\n",
      "ROI\n",
      "for\n",
      "investing\n",
      "in\n",
      "new\n",
      "films \n",
      "●\n",
      "Data\n",
      "mining\n",
      "and\n",
      "cleaning\n",
      "using\n",
      "SQL\n",
      "+\n",
      "pandas\n",
      "with\n",
      "around\n",
      "1500\n",
      "films\n",
      "as\n",
      "the\n",
      "final\n",
      "dataset \n",
      "●\n",
      "One\n",
      "way\n",
      "ANOVA\n",
      "hypothesis\n",
      "test,\n",
      "results\n",
      "showed\n",
      "genres\n",
      "have\n",
      "statistically\n",
      "different\n",
      "ROI\n",
      "s \n",
      "●\n",
      "Simple\n",
      "Linear\n",
      "Regression\n",
      "to\n",
      "compare\n",
      "Production\n",
      "Budget\n",
      "vs\n",
      "Revenue,\n",
      "recommend\n",
      "the\n",
      "film\n",
      "studio\n",
      "to\n",
      "adopt\n",
      "a\n",
      "low \n",
      "budget\n",
      "approach\n",
      "EXPERIENCE\n",
      "Business\n",
      "Analyst\n",
      "+\n",
      "Consultant,\n",
      "EverHealth\n",
      "Industrial\n",
      "CO,\n",
      "Guangzhou,\n",
      "CN\n",
      "Aug\n",
      "2016\n",
      "-\n",
      "Present \n",
      "●\n",
      "Built\n",
      "supply\n",
      "chain\n",
      "software\n",
      "and\n",
      "ecommerce\n",
      "platforms\n",
      "using\n",
      "Logiwa \n",
      "●\n",
      "Advised\n",
      "on\n",
      "manufacturing\n",
      "to\n",
      "lower\n",
      "costs\n",
      "of\n",
      "goods\n",
      "+\n",
      "products\n",
      "Sales\n",
      "Manager,\n",
      "Juliano\n",
      "Celini\n",
      "Inc\n",
      ",\n",
      "Sun\n",
      "Valley,\n",
      "CA\n",
      "2013-2022 \n",
      "●\n",
      "Created\n",
      "end\n",
      "to\n",
      "end\n",
      "ecommerce\n",
      "solutions\n",
      "for\n",
      "a\n",
      "traditional\n",
      "retail\n",
      "business \n",
      "●\n",
      "Terrapeak,\n",
      "Shopify,\n",
      "Amazon\n",
      "FBA\n",
      "QA\n",
      "Intern,\n",
      "Doremi\n",
      "Cinema\n",
      ",\n",
      "Burbank,\n",
      "CA\n",
      "2010-2012 \n",
      "●\n",
      "Storage\n",
      "and\n",
      "RAM\n",
      "testing\n",
      "for\n",
      "IMS\n",
      "prototype \n",
      "●\n",
      "Built\n",
      "tests\n",
      "for\n",
      "IMS\n",
      "prototype\n",
      "EDUCATIONFlatironSchool,NewYork,NY\n",
      "10/2023\n",
      "-\n",
      "02/2024ImmersiveDataScienceBootcamp\n",
      "Cal\n",
      "State\n",
      "Northridge\n",
      ",\n",
      "Northridge,\n",
      "CA\n",
      "2016 \n",
      "Communications\n",
      "Studies\n",
      "@\n",
      "Cal\n",
      "State\n",
      "Northridge\n"
     ]
    }
   ],
   "source": [
    "from pypdf import PdfReader\n",
    "\n",
    "reader = PdfReader('resume_1.pdf')\n",
    "number_of_pages = len(reader.pages)\n",
    "text = ''.join([page.extract_text() for page in reader.pages])\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fc3c0f00-e21f-4e72-a32a-f2e8aff516c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<pypdf._reader.PdfReader object at 0x7fce1be714e0>\n"
     ]
    }
   ],
   "source": [
    "print(reader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6391ff47-3d9c-485a-8dfe-1f3229735996",
   "metadata": {},
   "outputs": [],
   "source": [
    "from anthropic import Anthropic\n",
    "client = Anthropic()\n",
    "MODEL_NAME = \"claude-3-opus-20240229\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a95337b0-00bb-41e8-8ee5-80e76689f244",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_completion(client, prompt):\n",
    "    return client.messages.create(\n",
    "        model=MODEL_NAME,\n",
    "        max_tokens=2048,\n",
    "        messages=[{\n",
    "            \"role\": 'user', \"content\":  prompt\n",
    "        }]\n",
    "    ).content[0].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "16f7a504-4bc9-4824-b616-c69b3a30d84c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thanks for sharing your resume, Patrick. I have a few questions to better understand your background and goals:\n",
      "\n",
      "1. What specific data science roles are you targeting (e.g. data scientist, machine learning engineer, etc.)?\n",
      "\n",
      "2. Do you have a preference for particular industries you'd like to work in? \n",
      "\n",
      "3. Are there any key skills or experiences you want to make sure are highlighted?\n",
      "\n",
      "4. Any page length requirements to keep in mind?\n",
      "\n",
      "Based on your resume, here are some suggestions to enhance its impact:\n",
      "\n",
      "Structure & Formatting:\n",
      "- Move your Technical Skills section above Experience, since your skills seem highly relevant to data science roles\n",
      "- Consider adding an Education section, even if briefly, to show your relevant background\n",
      "- Use consistent date formatting and tense throughout (past tense for previous roles)\n",
      "- Left-align all content for easier scanning; avoid centering headings\n",
      "- Add a bit more white space between sections for readability\n",
      "\n",
      "Highlighting Skills & Achievements:\n",
      "- Lead with strong action verbs for each bullet, e.g. \"Built\", \"Created\", \"Analyzed\"\n",
      "- Quantify your impact with metrics where possible, e.g. \"built platforms that increased sales by X%\" \n",
      "- Focus project details on your specific role/contributions\n",
      "- Mention any key ML/AI techniques or algorithms used\n",
      "- Consider adding relevant coursework or skills from your degree\n",
      "\n",
      "Summary Statement:\n",
      "- Open with a concise tagline summarizing your unique value proposition \n",
      "- Alter the tone to be less casual - remove \"I\" statements \n",
      "- Tailor it more to your specific target roles \n",
      "\n",
      "Here's an example of how your edited resume could look:\n",
      "\n",
      "Patrick Yamin\n",
      "Los Angeles, CA | 909-569-4815 | patrickyamin@gmail.com  \n",
      "GitHub | Substack | LinkedIn\n",
      "\n",
      "DATA SCIENTIST | ML ENGINEER\n",
      "\n",
      "Experience in data mining, deep learning, machine learning, recommender systems and NLP. Background in analytics, supply chain logistics, and sales. Strong engineering skills in building and optimizing ML pipelines that drive innovation, efficiency and sustainability across industries.\n",
      "\n",
      "TECHNICAL SKILLS\n",
      "- Python (NumPy, Pandas, Scikit-Learn, PyTorch, Keras, OOP)  \n",
      "- SQL (MySQL, PostgreSQL, SQLite)\n",
      "- Bash, CUDA, Scripting, Virtualization, Docker\n",
      "- Tableau, Excel\n",
      "- OS: Linux (Arch, Debian, Pop!_OS, Ubuntu), macOS, Windows\n",
      "- Languages: Native English, Proficient Arabic, Limited Spanish & French\n",
      "\n",
      "PROJECTS\n",
      "Semantico (Semantic Search Engine) | GitHub\n",
      "- Built search engine using vector embeddings to efficiently query documents\n",
      "- Collected data via Wikipedia API calls\n",
      "- Trained BPE tokenizer with SentencePiece \n",
      "- Used SentenceTransformers SOTA PyTorch framework for end-to-end pipeline\n",
      "\n",
      "Pitch Sequence Predictor | GitHub  \n",
      "- Developed MLP neural network in scikit-learn to predict next pitch in MLB at-bats\n",
      "- Scraped data with pybaseball package (2023 season)\n",
      "- Achieved 60% validation accuracy with XGBoost model\n",
      "- Optimized with GridSearchCV and RandomizedSearchCV\n",
      "\n",
      "IMDb Film Statistical Analysis | GitHub\n",
      "- Analyzed 1500+ film database to maximize ROI for new movie investments  \n",
      "- Performed data mining and cleaning using SQL and pandas\n",
      "- Conducted ANOVA test, found statistically different ROI across genres\n",
      "- Built linear regression comparing budget vs revenue \n",
      "- Recommended low-budget approach to maximize returns\n",
      "\n",
      "EXPERIENCE\n",
      "EverHealth Industrial CO, Guangzhou, China\n",
      "Business Analyst + Consultant, Aug 2016 - Present\n",
      "- Built supply chain software and e-commerce platforms using Logiwa\n",
      "- Consulted on manufacturing to reduce product costs\n",
      "\n",
      "Juliano Celini Inc, Sun Valley, CA\n",
      "Sales Manager, 2013 - 2022  \n",
      "- Created end-to-end e-commerce solutions (Terrapeak, Shopify, Amazon FBA)\n",
      "- Transitioned traditional retail business to digital channels\n",
      "\n",
      "Doremi Cinema, Burbank, CA\n",
      "QA Intern, 2010 - 2012\n",
      "- Tested storage and RAM for IMS prototype\n",
      "- Developed test scripts and processes for IMS\n",
      "\n",
      "EDUCATION\n",
      "Flatiron School, New York, NY\n",
      "Immersive Data Science Bootcamp, Oct 2023 - Feb 2024\n",
      "\n",
      "California State University, Northridge \n",
      "B.A. Communications Studies, 2016\n",
      "\n",
      "I aimed to sharpen the focus on your data science skills and experience, while adding some concrete examples of your impact. The projects help demonstrate your technical capabilities. Let me know if you have any other questions!\n"
     ]
    }
   ],
   "source": [
    "completion = get_completion(client,\n",
    "    f\"\"\"Here is a resume: <resume>{text}</resume>\n",
    "\n",
    "Please do the following:\n",
    "1. Ask clarifying questions to understand their background, experience, career goals, and any specific requirements for their desired roles. \\n \\n2. Provide tailored advice on structuring and formatting their resume based on their situation, including section order, content suggestions, keyword optimization, and formatting tips. \\n \\n3. Recommend strategies for highlighting their most relevant skills, achievements, and experiences in a concise and compelling way that aligns with what employers are seeking. \\n \\n4. Offer guidance on ensuring consistency in areas like date formatting, tenses, personal pronouns usage, and writing style throughout the resume. \\n \\n5. Suggest ways to make their resume accomplishments-driven by using quantifiable metrics, hard numbers, and concrete examples wherever possible. \\n \\n6. Give feedback on refining their professional summary or resume objective statement to immediately capture an employer's attention. \\n \\n7. Output a fully edited version that takes into account all your suggestions. \\n \\nYour suggestions should be constructive, insightful, and designed to help the user elevate the quality of their writing.\"\n",
    "\"\"\"\n",
    ")\n",
    "print(completion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0453347e-1a98-45c7-b3c7-ce2c1638d6c2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
